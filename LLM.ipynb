{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":6971638,"sourceType":"datasetVersion","datasetId":3961875}],"dockerImageVersionId":31041,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-06-02T18:08:17.153606Z","iopub.execute_input":"2025-06-02T18:08:17.154340Z","iopub.status.idle":"2025-06-02T18:08:17.170111Z","shell.execute_reply.started":"2025-06-02T18:08:17.154308Z","shell.execute_reply":"2025-06-02T18:08:17.169324Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/llm-7-prompt-training-dataset/train_essays_RDizzl3_seven_v2.csv\n/kaggle/input/llm-7-prompt-training-dataset/train_essays_7_prompts_v2.csv\n/kaggle/input/llm-7-prompt-training-dataset/train_essays_7_prompts.csv\n/kaggle/input/llm-7-prompt-training-dataset/train_essays_RDizzl3_seven_v1.csv\n","output_type":"stream"}],"execution_count":17},{"cell_type":"code","source":"import pandas as pd\ndf1=pd.read_csv('/kaggle/input/llm-7-prompt-training-dataset/train_essays_7_prompts.csv')\ndf2=pd.read_csv('/kaggle/input/llm-7-prompt-training-dataset/train_essays_7_prompts_v2.csv')\ndf3=pd.read_csv('/kaggle/input/llm-7-prompt-training-dataset/train_essays_RDizzl3_seven_v1.csv')\ndf4=pd.read_csv('/kaggle/input/llm-7-prompt-training-dataset/train_essays_RDizzl3_seven_v2.csv')\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-02T18:08:17.171278Z","iopub.execute_input":"2025-06-02T18:08:17.171801Z","iopub.status.idle":"2025-06-02T18:08:18.615673Z","shell.execute_reply.started":"2025-06-02T18:08:17.171785Z","shell.execute_reply":"2025-06-02T18:08:18.615121Z"}},"outputs":[],"execution_count":18},{"cell_type":"code","source":"\nprint(f'df1 shape:',df1.shape)\nprint(f'df2 shape:',df2.shape)\nprint(f'df3 shape:',df3.shape)\nprint(f'df4 shape:',df4.shape)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-02T18:08:18.616370Z","iopub.execute_input":"2025-06-02T18:08:18.616633Z","iopub.status.idle":"2025-06-02T18:08:18.621659Z","shell.execute_reply.started":"2025-06-02T18:08:18.616610Z","shell.execute_reply":"2025-06-02T18:08:18.620950Z"}},"outputs":[{"name":"stdout","text":"df1 shape: (14877, 2)\ndf2 shape: (15350, 2)\ndf3 shape: (15871, 2)\ndf4 shape: (17251, 2)\n","output_type":"stream"}],"execution_count":19},{"cell_type":"code","source":"print(df1.columns)\nprint(df2.columns)\nprint(df3.columns)\nprint(df4.columns)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-02T18:08:18.623327Z","iopub.execute_input":"2025-06-02T18:08:18.623538Z","iopub.status.idle":"2025-06-02T18:08:18.642163Z","shell.execute_reply.started":"2025-06-02T18:08:18.623523Z","shell.execute_reply":"2025-06-02T18:08:18.641577Z"}},"outputs":[{"name":"stdout","text":"Index(['text', 'label'], dtype='object')\nIndex(['text', 'label'], dtype='object')\nIndex(['text', 'label'], dtype='object')\nIndex(['text', 'label'], dtype='object')\n","output_type":"stream"}],"execution_count":20},{"cell_type":"code","source":"df_all = pd.concat([df1, df2, df3, df4], ignore_index=True)\nprint(df_all.shape)\ndf_all.head()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-02T18:08:18.642865Z","iopub.execute_input":"2025-06-02T18:08:18.643148Z","iopub.status.idle":"2025-06-02T18:08:18.665044Z","shell.execute_reply.started":"2025-06-02T18:08:18.643132Z","shell.execute_reply":"2025-06-02T18:08:18.664366Z"}},"outputs":[{"name":"stdout","text":"(63349, 2)\n","output_type":"stream"},{"execution_count":21,"output_type":"execute_result","data":{"text/plain":"                                                text  label\n0  Cars. Cars have been around since they became ...      0\n1  Transportation is a large necessity in most co...      0\n2  \"America's love affair with it's vehicles seem...      0\n3  How often do you ride in a car? Do you drive a...      0\n4  Cars are a wonderful thing. They are perhaps o...      0","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Cars. Cars have been around since they became ...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Transportation is a large necessity in most co...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>\"America's love affair with it's vehicles seem...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>How often do you ride in a car? Do you drive a...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Cars are a wonderful thing. They are perhaps o...</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":21},{"cell_type":"code","source":"print(f'nulls in dataset',df_all.isnull().sum())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-02T18:08:18.665697Z","iopub.execute_input":"2025-06-02T18:08:18.665954Z","iopub.status.idle":"2025-06-02T18:08:18.682188Z","shell.execute_reply.started":"2025-06-02T18:08:18.665929Z","shell.execute_reply":"2025-06-02T18:08:18.681506Z"}},"outputs":[{"name":"stdout","text":"nulls in dataset text     0\nlabel    0\ndtype: int64\n","output_type":"stream"}],"execution_count":22},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\ndf_all = df_all.sample(frac=1, random_state=42).reset_index(drop=True)\ntrain_df, val_df = train_test_split(df_all, test_size=0.1, random_state=42)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-02T18:08:18.682888Z","iopub.execute_input":"2025-06-02T18:08:18.683380Z","iopub.status.idle":"2025-06-02T18:08:18.711694Z","shell.execute_reply.started":"2025-06-02T18:08:18.683357Z","shell.execute_reply":"2025-06-02T18:08:18.711177Z"}},"outputs":[],"execution_count":23},{"cell_type":"code","source":"from torch.utils.data import Dataset, DataLoader\nimport torch\nfrom transformers import AutoTokenizer, AutoModelForSequenceClassification\n\nmodel_name = 'huawei-noah/TinyBERT_General_4L_312D'\ntokenizer = AutoTokenizer.from_pretrained(model_name)\n\n# Define your custom dataset\nclass MyDataset(Dataset):\n    def __init__(self, texts, labels, tokenizer, max_length=64):\n        self.encodings = tokenizer(\n            texts,\n            padding='max_length',      # pad to max_length\n            truncation=True,\n            max_length=max_length,     # shorter input to save memory\n            return_tensors='pt'        # directly return PyTorch tensors\n        )\n        self.labels = torch.tensor(labels)\n\n    def __getitem__(self, idx):\n        return {\n            'input_ids': self.encodings['input_ids'][idx],\n            'attention_mask': self.encodings['attention_mask'][idx],\n            'labels': self.labels[idx]\n        }\n\n    def __len__(self):\n        return len(self.labels)\n\n\n#####################################################\n\ntrain_texts = train_df['text'].tolist()\ntrain_labels = train_df['label'].tolist()\n\n# Prepare validation data\nval_texts = val_df['text'].tolist()\nval_labels = val_df['label'].tolist()\n\n# Create Dataset instances\ntrain_dataset = MyDataset(train_texts, train_labels, tokenizer)\nval_dataset = MyDataset(val_texts, val_labels, tokenizer)\n\n# Create DataLoaders\ntrain_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\nval_loader = DataLoader(val_dataset, batch_size=16, shuffle=False)\n\n# Create dataset and dataloader\ndataset = MyDataset(texts, labels, tokenizer)\nloader = DataLoader(dataset, batch_size=16, shuffle=True)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-02T18:08:18.712466Z","iopub.execute_input":"2025-06-02T18:08:18.712970Z","iopub.status.idle":"2025-06-02T18:09:48.121608Z","shell.execute_reply.started":"2025-06-02T18:08:18.712948Z","shell.execute_reply":"2025-06-02T18:09:48.120844Z"}},"outputs":[],"execution_count":24},{"cell_type":"code","source":"from transformers import AutoModelForSequenceClassification\ndevice = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\nprint(f\"Using device: {device}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-02T18:09:48.122482Z","iopub.execute_input":"2025-06-02T18:09:48.122700Z","iopub.status.idle":"2025-06-02T18:09:48.449289Z","shell.execute_reply.started":"2025-06-02T18:09:48.122683Z","shell.execute_reply":"2025-06-02T18:09:48.448330Z"}},"outputs":[{"name":"stdout","text":"Using device: cuda\n","output_type":"stream"}],"execution_count":25},{"cell_type":"code","source":"from transformers import AutoModelForSequenceClassification\n\nmodel_name = 'huawei-noah/TinyBERT_General_4L_312D'  \n\nmodel = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=2)\nmodel.to(device)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-02T18:09:48.451523Z","iopub.execute_input":"2025-06-02T18:09:48.451743Z","iopub.status.idle":"2025-06-02T18:09:48.672842Z","shell.execute_reply.started":"2025-06-02T18:09:48.451728Z","shell.execute_reply":"2025-06-02T18:09:48.672106Z"}},"outputs":[{"name":"stderr","text":"Some weights of BertForSequenceClassification were not initialized from the model checkpoint at huawei-noah/TinyBERT_General_4L_312D and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"execution_count":26,"output_type":"execute_result","data":{"text/plain":"BertForSequenceClassification(\n  (bert): BertModel(\n    (embeddings): BertEmbeddings(\n      (word_embeddings): Embedding(30522, 312, padding_idx=0)\n      (position_embeddings): Embedding(512, 312)\n      (token_type_embeddings): Embedding(2, 312)\n      (LayerNorm): LayerNorm((312,), eps=1e-12, elementwise_affine=True)\n      (dropout): Dropout(p=0.1, inplace=False)\n    )\n    (encoder): BertEncoder(\n      (layer): ModuleList(\n        (0-3): 4 x BertLayer(\n          (attention): BertAttention(\n            (self): BertSdpaSelfAttention(\n              (query): Linear(in_features=312, out_features=312, bias=True)\n              (key): Linear(in_features=312, out_features=312, bias=True)\n              (value): Linear(in_features=312, out_features=312, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=312, out_features=312, bias=True)\n              (LayerNorm): LayerNorm((312,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=312, out_features=1200, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=1200, out_features=312, bias=True)\n            (LayerNorm): LayerNorm((312,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n    )\n    (pooler): BertPooler(\n      (dense): Linear(in_features=312, out_features=312, bias=True)\n      (activation): Tanh()\n    )\n  )\n  (dropout): Dropout(p=0.1, inplace=False)\n  (classifier): Linear(in_features=312, out_features=2, bias=True)\n)"},"metadata":{}}],"execution_count":26},{"cell_type":"code","source":"from torch.optim import AdamW\noptimizer=AdamW(model.parameters(),lr=5e-5,eps=1e-8,weight_decay=0.01)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-02T18:09:48.673509Z","iopub.execute_input":"2025-06-02T18:09:48.673716Z","iopub.status.idle":"2025-06-02T18:09:48.678029Z","shell.execute_reply.started":"2025-06-02T18:09:48.673701Z","shell.execute_reply":"2025-06-02T18:09:48.677270Z"}},"outputs":[],"execution_count":27},{"cell_type":"code","source":"import torch\nprint(torch.cuda.is_available())\nprint(torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"No GPU found\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-02T18:09:48.678807Z","iopub.execute_input":"2025-06-02T18:09:48.679081Z","iopub.status.idle":"2025-06-02T18:09:48.694838Z","shell.execute_reply.started":"2025-06-02T18:09:48.679066Z","shell.execute_reply":"2025-06-02T18:09:48.694040Z"}},"outputs":[{"name":"stdout","text":"True\nTesla T4\n","output_type":"stream"}],"execution_count":28},{"cell_type":"code","source":"from transformers import get_scheduler\nfrom sklearn.metrics import classification_report\nfrom tqdm import tqdm\nimport torch\n\nnum_epochs = 2\n\n# Scheduler setup\nnum_training_steps = num_epochs * len(train_loader)\nscheduler = get_scheduler(\n    \"linear\",\n    optimizer=optimizer,\n    num_warmup_steps=0,\n    num_training_steps=num_training_steps\n)\n\nfor epoch in range(num_epochs):\n    model.train()\n    total_loss = 0\n\n    print(f\"\\nEpoch {epoch + 1}/{num_epochs}\")\n    for batch in tqdm(train_loader):\n        batch = {k: v.to(device) for k, v in batch.items()}\n\n        outputs = model(**batch)\n        loss = outputs.loss\n        total_loss += loss.item()\n\n        loss.backward()\n        optimizer.step()\n        scheduler.step()\n        optimizer.zero_grad()\n\n    avg_loss = total_loss / len(train_loader)\n    print(f\"Average training loss: {avg_loss:.4f}\")\n\n    # Evaluation on validation set\n    model.eval()\n    all_preds = []\n    all_labels = []\n\n    with torch.no_grad():\n        for batch in val_loader:\n            batch = {k: v.to(device) for k, v in batch.items()}\n            outputs = model(input_ids=batch['input_ids'], attention_mask=batch['attention_mask'])\n            logits = outputs.logits\n            preds = torch.argmax(logits, dim=-1)\n            all_preds.extend(preds.cpu().numpy())\n            all_labels.extend(batch['labels'].cpu().numpy())\n\n    print(\"Validation classification report:\")\n    print(classification_report(all_labels, all_preds, digits=4))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-02T18:09:48.695626Z","iopub.execute_input":"2025-06-02T18:09:48.695877Z","iopub.status.idle":"2025-06-02T18:11:52.673041Z","shell.execute_reply.started":"2025-06-02T18:09:48.695858Z","shell.execute_reply":"2025-06-02T18:11:52.672232Z"}},"outputs":[{"name":"stdout","text":"\nEpoch 1/2\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 3564/3564 [00:59<00:00, 59.88it/s]\n","output_type":"stream"},{"name":"stdout","text":"Average training loss: 0.0490\nValidation classification report:\n              precision    recall  f1-score   support\n\n           0     0.9980    0.9980    0.9980      5579\n           1     0.9854    0.9854    0.9854       756\n\n    accuracy                         0.9965      6335\n   macro avg     0.9917    0.9917    0.9917      6335\nweighted avg     0.9965    0.9965    0.9965      6335\n\n\nEpoch 2/2\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 3564/3564 [01:00<00:00, 58.43it/s]\n","output_type":"stream"},{"name":"stdout","text":"Average training loss: 0.0049\nValidation classification report:\n              precision    recall  f1-score   support\n\n           0     0.9995    0.9995    0.9995      5579\n           1     0.9960    0.9960    0.9960       756\n\n    accuracy                         0.9991      6335\n   macro avg     0.9977    0.9977    0.9977      6335\nweighted avg     0.9991    0.9991    0.9991      6335\n\n","output_type":"stream"}],"execution_count":29},{"cell_type":"code","source":"import torch\nfrom torch.nn import CrossEntropyLoss\n\nfrom collections import Counter\nlabel_counts = Counter(labels)  \ntotal_count = sum(label_counts.values())\n\nclass_weights = [total_count / label_counts[i] for i in range(len(label_counts))]\nclass_weights = torch.tensor(class_weights).to(device)\n\nloss_fn = CrossEntropyLoss(weight=class_weights)\n\noutputs = model(input_ids=batch['input_ids'], attention_mask=batch['attention_mask'])\nlogits = outputs.logits\n\nloss = loss_fn(logits, batch['labels'])\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-02T18:11:52.673913Z","iopub.execute_input":"2025-06-02T18:11:52.674195Z","iopub.status.idle":"2025-06-02T18:11:52.688213Z","shell.execute_reply.started":"2025-06-02T18:11:52.674173Z","shell.execute_reply":"2025-06-02T18:11:52.687506Z"}},"outputs":[],"execution_count":30},{"cell_type":"code","source":"from sklearn.metrics import classification_report\nimport numpy as np\n\nmodel.eval()\nall_preds = []\nall_labels = []\n\nwith torch.no_grad():\n    for batch in val_loader:  \n        batch = {k: v.to(device) for k, v in batch.items()}\n        outputs = model(input_ids=batch['input_ids'], attention_mask=batch['attention_mask'])\n        logits = outputs.logits\n        preds = torch.argmax(logits, dim=-1)\n\n        all_preds.extend(preds.cpu().numpy())\n        all_labels.extend(batch['labels'].cpu().numpy())\n\nprint(classification_report(all_labels, all_preds, digits=4))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-02T18:13:20.345207Z","iopub.execute_input":"2025-06-02T18:13:20.345794Z","iopub.status.idle":"2025-06-02T18:13:22.076227Z","shell.execute_reply.started":"2025-06-02T18:13:20.345773Z","shell.execute_reply":"2025-06-02T18:13:22.075357Z"}},"outputs":[{"name":"stdout","text":"              precision    recall  f1-score   support\n\n           0     0.9995    0.9995    0.9995      5579\n           1     0.9960    0.9960    0.9960       756\n\n    accuracy                         0.9991      6335\n   macro avg     0.9977    0.9977    0.9977      6335\nweighted avg     0.9991    0.9991    0.9991      6335\n\n","output_type":"stream"}],"execution_count":33},{"cell_type":"code","source":"model.save_pretrained(\"finetuned_distilbert\")\ntokenizer.save_pretrained(\"finetuned_distilbert\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-02T18:16:03.911668Z","iopub.execute_input":"2025-06-02T18:16:03.912288Z","iopub.status.idle":"2025-06-02T18:16:04.124211Z","shell.execute_reply.started":"2025-06-02T18:16:03.912250Z","shell.execute_reply":"2025-06-02T18:16:04.123385Z"}},"outputs":[{"execution_count":35,"output_type":"execute_result","data":{"text/plain":"('finetuned_distilbert/tokenizer_config.json',\n 'finetuned_distilbert/special_tokens_map.json',\n 'finetuned_distilbert/vocab.txt',\n 'finetuned_distilbert/added_tokens.json',\n 'finetuned_distilbert/tokenizer.json')"},"metadata":{}}],"execution_count":35},{"cell_type":"code","source":"#will check accuracy for unseen data \n\ndf_unseen = df_all.iloc[int(0.9 * len(df_all)):].copy()\n\n\ntexts_unseen = df_unseen['text'].tolist()\nlabels_unseen = df_unseen['label'].tolist()  \nencodings_unseen = tokenizer(texts_unseen, padding=True, truncation=True, max_length=512)\n\nclass MyDataset(Dataset):\n    def __init__(self, encodings, labels):\n        self.encodings = encodings\n        self.labels = labels\n\n    def __getitem__(self, idx):\n        return {\n            'input_ids': torch.tensor(self.encodings['input_ids'][idx]),\n            'attention_mask': torch.tensor(self.encodings['attention_mask'][idx]),\n            'labels': torch.tensor(self.labels[idx])\n        }\n\n    def __len__(self):\n        return len(self.labels)\n\nunseen_dataset = MyDataset(encodings_unseen, labels_unseen)\nunseen_loader = DataLoader(unseen_dataset, batch_size=16)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-02T18:28:34.285912Z","iopub.execute_input":"2025-06-02T18:28:34.286469Z","iopub.status.idle":"2025-06-02T18:28:38.518558Z","shell.execute_reply.started":"2025-06-02T18:28:34.286447Z","shell.execute_reply":"2025-06-02T18:28:38.517570Z"}},"outputs":[],"execution_count":39},{"cell_type":"code","source":"from sklearn.metrics import classification_report\n\nmodel.eval()\nall_preds = []\nall_labels = []\n\nwith torch.no_grad():\n    for batch in unseen_loader:\n        batch = {k: v.to(device) for k, v in batch.items()}\n        outputs = model(input_ids=batch['input_ids'], attention_mask=batch['attention_mask'])\n        preds = torch.argmax(outputs.logits, dim=-1)\n\n        all_preds.extend(preds.cpu().numpy())\n        all_labels.extend(batch['labels'].cpu().numpy())\n\nprint(classification_report(all_labels, all_preds, digits=4))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-02T18:28:45.964636Z","iopub.execute_input":"2025-06-02T18:28:45.965445Z","iopub.status.idle":"2025-06-02T18:29:02.092727Z","shell.execute_reply.started":"2025-06-02T18:28:45.965419Z","shell.execute_reply":"2025-06-02T18:29:02.091886Z"}},"outputs":[{"name":"stdout","text":"              precision    recall  f1-score   support\n\n           0     0.9743    0.9773    0.9758      5633\n           1     0.8131    0.7934    0.8032       702\n\n    accuracy                         0.9569      6335\n   macro avg     0.8937    0.8854    0.8895      6335\nweighted avg     0.9565    0.9569    0.9567      6335\n\n","output_type":"stream"}],"execution_count":40},{"cell_type":"code","source":"model.save_pretrained(\"my_model\")\ntokenizer.save_pretrained(\"my_model\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-02T18:40:59.586148Z","iopub.execute_input":"2025-06-02T18:40:59.586479Z","iopub.status.idle":"2025-06-02T18:40:59.784525Z","shell.execute_reply.started":"2025-06-02T18:40:59.586458Z","shell.execute_reply":"2025-06-02T18:40:59.783879Z"}},"outputs":[{"execution_count":48,"output_type":"execute_result","data":{"text/plain":"('my_model/tokenizer_config.json',\n 'my_model/special_tokens_map.json',\n 'my_model/vocab.txt',\n 'my_model/added_tokens.json',\n 'my_model/tokenizer.json')"},"metadata":{}}],"execution_count":48}]}